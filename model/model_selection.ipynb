{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, precision_score, recall_score, accuracy_score, brier_score_loss, log_loss\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import statsmodels.api as sm\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import itertools\n",
    "import random\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import pickle\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://meettank29067.medium.com/performance-measurement-in-logistic-regression-8c9109b25278"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pulling in the data\n",
    "### starting with predictALL for the large model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75\n",
      "Index(['name', 'wins', 'tko', 'sub', 'udec', 'sdec', 'height', 'weight',\n",
      "       'reach', 'dob', 'slpm', 'sapm', 'strAcc', 'strDef', 'hslpm', 'hsapm',\n",
      "       'hstrAcc', 'bslpm', 'bsapm', 'bstrAcc', 'lslpm', 'lsapm', 'lstrAcc',\n",
      "       'dslpm', 'dsapm', 'dstrAcc', 'cslpm', 'csapm', 'cstrAcc', 'gslpm',\n",
      "       'gsapm', 'gstrAcc', 'tdAvg', 'tdAcc', 'tdDef', 'subAvg', 'ctrlAvg',\n",
      "       'name1', 'wins1', 'tko1', 'sub1', 'udec1', 'sdec1', 'height1',\n",
      "       'weight1', 'reach1', 'dob1', 'slpm1', 'sapm1', 'strAcc1', 'strDef1',\n",
      "       'hslpm1', 'hsapm1', 'hstrAcc1', 'bslpm1', 'bsapm1', 'bstrAcc1',\n",
      "       'lslpm1', 'lsapm1', 'lstrAcc1', 'dslpm1', 'dsapm1', 'dstrAcc1',\n",
      "       'cslpm1', 'csapm1', 'cstrAcc1', 'gslpm1', 'gsapm1', 'gstrAcc1',\n",
      "       'tdAvg1', 'tdAcc1', 'tdDef1', 'subAvg1', 'ctrlAvg1', 'winner'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "filepath = os.path.join(os.path.abspath(\"..\"), \"ETL\", \"modelData\", \"modelLarge.json\")\n",
    "data = pd.read_json(filepath)\n",
    "print(len(data.columns))\n",
    "print(data.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I will run best subset and see if it makes sense\n",
    "## then ill run best subset on my selected model\n",
    "## I think a good model will include \n",
    "- tko\n",
    "- sub\n",
    "- udec\n",
    "- sdec\n",
    "- height\n",
    "- reach\n",
    "- dob\n",
    "- strapm\n",
    "- strAcc   \n",
    "- strDef\n",
    "- hstrAcc\n",
    "- bstrAcc\n",
    "- lstrAcc\n",
    "- dstrAcc\n",
    "- cstrAcc\n",
    "- gstrAcc\n",
    "- tdAvg\n",
    "- TdAcc\n",
    "- tdDef\n",
    "- subAvg\n",
    "- ctrlAvg\n",
    "\n",
    "  - try best subset where we just change strAcc preditctors. \n",
    "    - this way we can use all other predictors and find out exactly which of these matters\n",
    "    - first model will have strAcc \n",
    "    - second will have all other acc \n",
    "    - best subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the scaler\n",
    "scaler = StandardScaler()\n",
    "# iterate over the numerical columns and use this z-score to normalize\n",
    "# probably not needed, but will want to try on things like wins, tko, age, height\n",
    "# each normilizatoin step increases data complexity alot once we get to the \n",
    "# weightclass models \n",
    "# Now use the scaled features to train your logistic regression model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the Variance inflation factor of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name\n",
      "name1\n",
      "Index(['wins', 'tko', 'sub', 'udec', 'sdec', 'height', 'weight', 'reach',\n",
      "       'dob', 'slpm', 'sapm', 'strAcc', 'strDef', 'hslpm', 'hsapm', 'hstrAcc',\n",
      "       'bslpm', 'bsapm', 'bstrAcc', 'lslpm', 'lsapm', 'lstrAcc', 'dslpm',\n",
      "       'dsapm', 'dstrAcc', 'cslpm', 'csapm', 'cstrAcc', 'gslpm', 'gsapm',\n",
      "       'gstrAcc', 'tdAvg', 'tdAcc', 'tdDef', 'subAvg', 'ctrlAvg', 'wins1',\n",
      "       'tko1', 'sub1', 'udec1', 'sdec1', 'height1', 'weight1', 'reach1',\n",
      "       'dob1', 'slpm1', 'sapm1', 'strAcc1', 'strDef1', 'hslpm1', 'hsapm1',\n",
      "       'hstrAcc1', 'bslpm1', 'bsapm1', 'bstrAcc1', 'lslpm1', 'lsapm1',\n",
      "       'lstrAcc1', 'dslpm1', 'dsapm1', 'dstrAcc1', 'cslpm1', 'csapm1',\n",
      "       'cstrAcc1', 'gslpm1', 'gsapm1', 'gstrAcc1', 'tdAvg1', 'tdAcc1',\n",
      "       'tdDef1', 'subAvg1', 'ctrlAvg1', 'winner'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "numerical_cols = pd.DataFrame()\n",
    "for col in data.columns:\n",
    "    if data[col].dtype != \"object\":\n",
    "        numerical_cols[col] = data[col]\n",
    "    else:\n",
    "        print(col)\n",
    "# I need to make the result numeric for 0-1\n",
    "print(numerical_cols.columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vif = pd.DataFrame()\n",
    "# vif[\"Variable\"] = numerical_cols.columns\n",
    "# vif[\"VIF\"] = [sm.OLS(numerical_cols[col], numerical_cols.drop(col, axis=1)).fit().rsquared for col in numerical_cols.columns]\n",
    "# for i in range(len(vif)):\n",
    "#     factor = 1/(1-vif.loc[i][1])\n",
    "#     print(vif.loc[i][\"Variable\"],factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Index  y_test  y_pred\n",
      "0     2353       0       0\n",
      "1     2066       0       0\n",
      "2     3175       1       1\n",
      "3     3452       0       0\n",
      "4     1604       0       0\n",
      "..     ...     ...     ...\n",
      "960    891       0       1\n",
      "961   2732       0       0\n",
      "962   3426       1       0\n",
      "963   2883       1       0\n",
      "964    294       0       0\n",
      "\n",
      "[965 rows x 3 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kristopherbyington/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(max_iter=5000)\n",
    "# MAIN metric is BIC\n",
    "# precision -> tp / (tp + fp) :: how precisce are true predictions\n",
    "# recall -> tp / (tp + fn) :: all true predictions \n",
    "# accuracy -> (tp + tn) / total :: total correct\n",
    "modelData = data.drop([\"name\",\"name1\"], axis=1)\n",
    "x_train, x_test, y_train, y_test = train_test_split(modelData.drop([\"winner\"],axis=1), \n",
    "                                                    modelData[\"winner\"], \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=43)\n",
    "\n",
    "model = model.fit(x_train, y_train)\n",
    "y_predicted = model.predict(x_test)\n",
    "results = pd.DataFrame({\"Index\":y_test.index.values,\n",
    "                        \"y_test\": y_test.values,\n",
    "                        \"y_pred\": y_predicted} )\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## metrics for model with all 72 predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.4514333045231922\n",
      "Recall: 0.4593913007274176\n",
      "Accuracy: 0.6766839378238342\n",
      "BIC: 261.8138509283035\n",
      "Predictors: [['wins', 'tko', 'sub', 'udec', 'sdec', 'height', 'weight', 'reach', 'dob', 'slpm', 'sapm', 'strAcc', 'strDef', 'hslpm', 'hsapm', 'hstrAcc', 'bslpm', 'bsapm', 'bstrAcc', 'lslpm', 'lsapm', 'lstrAcc', 'dslpm', 'dsapm', 'dstrAcc', 'cslpm', 'csapm', 'cstrAcc', 'gslpm', 'gsapm', 'gstrAcc', 'tdAvg', 'tdAcc', 'tdDef', 'subAvg', 'ctrlAvg', 'wins1', 'tko1', 'sub1', 'udec1', 'sdec1', 'height1', 'weight1', 'reach1', 'dob1', 'slpm1', 'sapm1', 'strAcc1', 'strDef1', 'hslpm1', 'hsapm1', 'hstrAcc1', 'bslpm1', 'bsapm1', 'bstrAcc1', 'lslpm1', 'lsapm1', 'lstrAcc1', 'dslpm1', 'dsapm1', 'dstrAcc1', 'cslpm1', 'csapm1', 'cstrAcc1', 'gslpm1', 'gsapm1', 'gstrAcc1', 'tdAvg1', 'tdAcc1', 'tdDef1', 'subAvg1', 'ctrlAvg1']]\n",
      "number of predictors: 73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kristopherbyington/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# MAIN metric is BIC\n",
    "# precision -> tp / (tp + fp) :: true pos / all true\n",
    "# recall -> tp / (tp + fn) :: true predictions / actual true in data\n",
    "# accuracy -> (tp + tn) / total :: total correct\n",
    "# Calculate precision\n",
    "def printMetrics(model, results):\n",
    "    precision = precision_score(results[\"y_test\"], results[\"y_pred\"], average=\"macro\")\n",
    "\n",
    "    # # Calculate recall\n",
    "    recall = recall_score(results[\"y_test\"], results[\"y_pred\"], average=\"macro\")\n",
    "\n",
    "    # # Calculate accuracy\n",
    "    accuracy = accuracy_score(results[\"y_test\"], results[\"y_pred\"])\n",
    "\n",
    "    # print(results[\"y_test\"].values, results[\"y_pred\"])\n",
    "    # # Calculate BIC\n",
    "    # BIC is not a standard metric provided by scikit-learn, but you can calculate it using log_loss\n",
    "    log_loss_value = log_loss(results[\"y_test\"].values, results[\"y_pred\"].values,labels=[0, 1])\n",
    "    n = len(results[\"y_test\"])  # Number of samples\n",
    "    p = len(model.coef_[0]) + 1  # Number of parameters (including intercept)\n",
    "    bic = log_loss_value + 0.5 * p * np.log(n)\n",
    "\n",
    "    predictors = [list(model.feature_names_in_)]\n",
    "\n",
    "    print(f\"Precision: {precision}\")\n",
    "    print(f\"Recall: {recall}\")\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(f\"BIC: {bic}\")\n",
    "    print(f\"Predictors: {predictors}\")\n",
    "    print(f\"number of predictors: {p}\")\n",
    "printMetrics(model, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.4518064516129032\n",
      "Recall: 0.46026711632139605\n",
      "Accuracy: 0.677720207253886\n",
      "BIC: 117.46180986403027\n",
      "Predictors: [['wins', 'wins1', 'tko', 'tko1', 'udec', 'udec1', 'sdec', 'sdec1', 'height', 'height1', 'reach', 'reach1', 'dob', 'dob1', 'sapm', 'sapm1', 'strDef', 'strDef1', 'strAcc', 'strAcc1', 'tdAvg', 'tdAvg1', 'tdAcc', 'tdAcc1', 'tdDef', 'tdDef1', 'subAvg', 'subAvg1', 'ctrlAvg', 'ctrlAvg1']]\n",
      "number of predictors: 31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kristopherbyington/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kristopherbyington/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "base_model_predictors = [\n",
    "    \"wins\",\n",
    "    \"wins1\",\n",
    "    \"tko\",\n",
    "    \"tko1\",\n",
    "    \"udec\",\n",
    "    \"udec1\",\n",
    "    \"sdec\",\n",
    "    \"sdec1\",\n",
    "    \"height\",\n",
    "    \"height1\",\n",
    "    \"reach\",\n",
    "    \"reach1\",\n",
    "    \"dob\",\n",
    "    \"dob1\",\n",
    "    \"sapm\",\n",
    "    \"sapm1\",\n",
    "    \"strDef\",\n",
    "    \"strDef1\",\n",
    "    \"strAcc\",\n",
    "    \"strAcc1\",\n",
    "    \"tdAvg\",\n",
    "    \"tdAvg1\",\n",
    "    \"tdAcc\",\n",
    "    \"tdAcc1\",\n",
    "    \"tdDef\",\n",
    "    \"tdDef1\",\n",
    "    \"subAvg\",\n",
    "    \"subAvg1\",\n",
    "    \"ctrlAvg\",\n",
    "    \"ctrlAvg1\",\n",
    "    \"winner\"\n",
    "]\n",
    "base_data = modelData[base_model_predictors]\n",
    "base_model = LogisticRegression(max_iter=5000)\n",
    "# MAIN metric is BIC\n",
    "# precision -> tp / (tp + fp) :: how precisce are true predictions\n",
    "# recall -> tp / (tp + fn) :: all true predictions \n",
    "# accuracy -> (tp + tn) / total :: total correct\n",
    "x_train, x_test, y_train, y_test = train_test_split(base_data.drop([\"winner\"],axis=1), \n",
    "                                                    base_data[\"winner\"], \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=43)\n",
    "\n",
    "base_model = model.fit(x_train, y_train)\n",
    "y_predicted = model.predict(x_test)\n",
    "results = pd.DataFrame({\"Index\":y_test.index.values,\n",
    "                        \"y_test\": y_test.values,\n",
    "                        \"y_pred\": y_predicted} )\n",
    "printMetrics(base_model, results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.46077419354838706\n",
      "Recall: 0.4694118801634459\n",
      "Accuracy: 0.6911917098445596\n",
      "BIC: 151.33688820071637\n",
      "Predictors: [['wins', 'wins1', 'tko', 'tko1', 'udec', 'udec1', 'sdec', 'sdec1', 'height', 'height1', 'reach', 'reach1', 'dob', 'dob1', 'sapm', 'sapm1', 'strDef', 'strDef1', 'hstrAcc', 'hstrAcc1', 'bstrAcc', 'bstrAcc1', 'lstrAcc', 'lstrAcc1', 'dstrAcc', 'dstrAcc1', 'cstrAcc', 'cstrAcc1', 'gstrAcc', 'gstrAcc1', 'tdAvg', 'tdAvg1', 'tdAcc', 'tdAcc1', 'tdDef', 'tdDef1', 'subAvg', 'subAvg1', 'ctrlAvg', 'ctrlAvg1']]\n",
      "number of predictors: 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kristopherbyington/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kristopherbyington/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "spread_str_predictors = [\n",
    "    \"wins\",\n",
    "    \"wins1\",\n",
    "    \"tko\",\n",
    "    \"tko1\",\n",
    "    \"udec\",\n",
    "    \"udec1\",\n",
    "    \"sdec\",\n",
    "    \"sdec1\",\n",
    "    \"height\",\n",
    "    \"height1\",\n",
    "    \"reach\",\n",
    "    \"reach1\",\n",
    "    \"dob\",\n",
    "    \"dob1\",\n",
    "    \"sapm\",\n",
    "    \"sapm1\",\n",
    "    \"strDef\",\n",
    "    \"strDef1\",\n",
    "    # \"strAcc\",\n",
    "    # \"strAcc1\",\n",
    "    \"hstrAcc\",\n",
    "    \"hstrAcc1\",\n",
    "    \"bstrAcc\",\n",
    "    \"bstrAcc1\",\n",
    "    \"lstrAcc\",\n",
    "    \"lstrAcc1\",\n",
    "    \"dstrAcc\",\n",
    "    \"dstrAcc1\",\n",
    "    \"cstrAcc\",\n",
    "    \"cstrAcc1\",\n",
    "    \"gstrAcc\",\n",
    "    \"gstrAcc1\",\n",
    "    \"tdAvg\",\n",
    "    \"tdAvg1\",\n",
    "    \"tdAcc\",\n",
    "    \"tdAcc1\",\n",
    "    \"tdDef\",\n",
    "    \"tdDef1\",\n",
    "    \"subAvg\",\n",
    "    \"subAvg1\",\n",
    "    \"ctrlAvg\",\n",
    "    \"ctrlAvg1\",\n",
    "    \"winner\"\n",
    "]\n",
    "spread_str_data = modelData[spread_str_predictors]\n",
    "spread_model = LogisticRegression(max_iter=5000)\n",
    "# MAIN metric is BIC\n",
    "# precision -> tp / (tp + fp) :: how precisce are true predictions\n",
    "# recall -> tp / (tp + fn) :: all true predictions \n",
    "# accuracy -> (tp + tn) / total :: total correct\n",
    "x_train, x_test, y_train, y_test = train_test_split(spread_str_data.drop([\"winner\"],axis=1), \n",
    "                                                    spread_str_data[\"winner\"], \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=43)\n",
    "\n",
    "spread_model = model.fit(x_train, y_train)\n",
    "y_predicted = model.predict(x_test)\n",
    "results = pd.DataFrame({\"Index\":y_test.index.values,\n",
    "                        \"y_test\": y_test.values,\n",
    "                        \"y_pred\": y_predicted} )\n",
    "printMetrics(spread_model, results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
